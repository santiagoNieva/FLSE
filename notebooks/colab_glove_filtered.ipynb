{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLSE distillation con GloVe o vocab filtrado\n",
    "\n",
    "Notebook breve para probar:\n",
    "- Teacher GloVe 6B (300d, inglés)\n",
    "- Teacher fastText es filtrado (solo tokens alfabéticos) en un vocab recortado\n",
    "- Entrenamiento 5 capas con temperaturas por capa\n",
    "- Vecinos filtrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup repo\n",
    "Clona y prepara entorno editable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/santiagoNieva/FLSE.git\n",
    "%cd FLSE\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Teacher GloVe 6B (300d)\n",
    "Descarga con torchtext y guarda .npy (usa inglés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchtext\n",
    "import numpy as np\n",
    "from torchtext.vocab import GloVe\n",
    "glove = GloVe(name='6B', dim=300)\n",
    "np.save('/content/FLSE/teacher_glove6B_300.npy', glove.vectors.numpy())\n",
    "# vocab size ~400k, dim=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Teacher fastText es filtrado (solo alfabético, recorte 100k)\n",
    "Útil para reducir ruido de signos/siglas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O /content/cc.es.300.bin.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.bin.gz\n",
    "!gunzip /content/cc.es.300.bin.gz\n",
    "\n",
    "import fasttext, numpy as np\n",
    "ft = fasttext.load_model('/content/cc.es.300.bin')\n",
    "raw_words = ft.words\n",
    "keep = [w for w in raw_words if w.isalpha() and len(w)>2][:100000]\n",
    "vecs = np.vstack([ft.get_word_vector(w) for w in keep])\n",
    "np.save('/content/FLSE/teacher_fasttext_es_100k_clean.npy', vecs)\n",
    "np.save('/content/FLSE/teacher_fasttext_es_100k_vocab.npy', np.array(keep))\n",
    "# vocab size 100k, dim=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Entrenamiento (ejemplo con GloVe, 5 capas)\n",
    "Ajusta temps/targets según necesidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python experiments/distill_playground.py \\\n",
    "  --teacher-path /content/FLSE/teacher_glove6B_300.npy \\\n",
    "  --vocab-size 400000 --teacher-dim 300 \\\n",
    "  --num-layers 5 --verts-per-layer 12 --dim 12 \\\n",
    "  --epochs 10 --batch-size 64 \\\n",
    "  --lambda-ent 8.0 \\\n",
    "  --lambda-entropies 1.0 1.5 2.5 3.0 3.0 \\\n",
    "  --target-entropies 1.6 1.0 0.8 0.5 0.35 \\\n",
    "  --logit-temps 1.0 1.5 2.0 2.5 2.7 \\\n",
    "  --device cuda \\\n",
    "  --save-path /content/FLSE/data/flse_glove5c.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Entrenamiento (ejemplo con fastText limpio 100k)\n",
    "Mismo set de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python experiments/distill_playground.py \\\n",
    "  --teacher-path /content/FLSE/teacher_fasttext_es_100k_clean.npy \\\n",
    "  --vocab-size 100000 --teacher-dim 300 \\\n",
    "  --num-layers 5 --verts-per-layer 12 --dim 12 \\\n",
    "  --epochs 12 --batch-size 64 \\\n",
    "  --lambda-ent 9.0 \\\n",
    "  --lambda-entropies 1.0 1.5 2.5 3.0 3.0 \\\n",
    "  --target-entropies 1.6 1.0 0.8 0.5 0.35 \\\n",
    "  --logit-temps 1.0 1.5 2.0 2.5 2.7 \\\n",
    "  --device cuda \\\n",
    "  --save-path /content/FLSE/data/flse_fasttext_clean5c.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Cargar, vecinos filtrados y entropías\n",
    "Reutiliza el código de carga/vecinos del otro notebook ajustando rutas/paths de teacher y vocab (para fastText limpio carga `teacher_fasttext_es_100k_vocab.npy`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
